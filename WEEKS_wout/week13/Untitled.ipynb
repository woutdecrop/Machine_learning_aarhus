{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [ ]:\n",
    "# ## PCA on digits\n",
    "# In this exercise we will experiment with PCA on digits.\n",
    "\n",
    "# 1. Run PCA on the data (first 5000) http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html (use n_components = 784) and use ``plot_images`` to plot the 20 directions with largest variance. Use this PCA model for all subsequent computations. The directions can be found with the attribute ``components_``.\n",
    "# 2. Take the first 20 data points from the data and project them onto the first $k$ components for $k \\in \\{1, 2,4,8,16, 32, 64\\}$. Then plot them as images. What do you see?\n",
    "#     **Hint:** To project them compute the length of the projection of each point onto the first $k$ directions and then compute for each image compute the linear combination of the first $k$ directions given by these directions (XZZ^T as in lecture).\n",
    "# 3. Map all the data to 2D (the length of the projection on the first two directions) and make a scatter plot where you color with the label and see if there is some structure (use scatter with ``cmap = plt.cm.Paired``, like ``ax.scatter(x,y, c=lab, cmap=plt.cm.Paired)``)\n",
    "# 4. Map all data to $32$ dimensions and run an SGD Classifier and output in-sample accuracy. How should you select target dimension in real life?\n",
    "#    Use the following classifer (svm loss): ``clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)``\n",
    "\n",
    "# Discuss the results. Are they what you expect? Why? Why not.\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Load full dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "\n",
    "\n",
    "\n",
    "def plot_images(dat, k=20, size=28):\n",
    "    \"\"\" Plot the first k vectors as 28 x 28 images \"\"\"\n",
    "    x2 = dat[0:k,:].reshape(-1, size, size)\n",
    "    x2 = x2.transpose(1, 0, 2)\n",
    "    fig, ax = plt.subplots(figsize=(20,12))\n",
    "    ax.imshow(x2.reshape(size, -1), cmap='bone')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    plt.show()\n",
    "\n",
    "#data, labels =\n",
    "data = mnist_trainset.data.numpy().reshape((60000, 28*28))\n",
    "labels = mnist_trainset.targets.numpy()\n",
    "\n",
    "# reduce size for speed\n",
    "rp = np.random.permutation(len(labels))\n",
    "dat = data[rp[:5000], :]\n",
    "lab = labels[rp[:5000]]\n",
    "\n",
    "components = None\n",
    "## TASK 1\n",
    "### YOUR CODE HERE\n",
    "### END CODE\n",
    "print('First 20 directions (eigenvectors X^T X)')\n",
    "plot_images(components, 20)\n",
    "\n",
    "## TASK 2\n",
    "# take the first 20 data point and project them onto the first k components and plot for k in [1, 2,4,8,16, 32, 64]\n",
    "img = dat[0:20, :]\n",
    "print('Original images:')\n",
    "plot_images(img, 20)\n",
    "for k in [1, 2, 4, 8, 16, 32, 64]:\n",
    "    ### YOUR CODE HERE\n",
    "    ### END CODE\n",
    "    \n",
    "# map the data to 2D and plot the results colored by label\n",
    "proj = None\n",
    "## TASK 3\n",
    "### YOUR CODE HERE\n",
    "### END CODE\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "ax.scatter(proj[:,0], proj[:,1], c=lab, cmap=plt.cm.Paired)\n",
    "plt.show()\n",
    "\n",
    "## TASK 4\n",
    "clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def plot_images(dat, k=16):\n",
    "    \"\"\" Plot the first k vectors as 28 x 28 images \"\"\"\n",
    "    size = 28 \n",
    "    x2 = dat[0:k,:].reshape(-1, size, size)\n",
    "    x2 = x2.transpose(1, 0, 2)\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    ax.imshow(x2.reshape(size, -1), cmap='bone')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle=False)\n",
    "# works like this \n",
    "for idx, (X, y) in enumerate(train_loader):\n",
    "    x_vec = X.reshape(-1, 784)\n",
    "    print('Input Images')\n",
    "    plot_images(x_vec.numpy(), k=x_vec.shape[0]) # move to numpy only relevant when needing data in that format\n",
    "    if idx > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" The paramters required to be set by fit method \"\"\"\n",
    "        self.W1 = None\n",
    "        self.b1 = None\n",
    "        self.W2 = None\n",
    "        self.b2 = None\n",
    "\n",
    "    def cost(self, X, W1, b1, W2, b2):\n",
    "        \"\"\" Compute (Regularized) Least Squares Loss of neural net\n",
    "        The clamp function may be usefull\n",
    "        \n",
    "          X: torch.tensor shape (n, d) - Data\n",
    "          W1: torch.tensor shape (d, h) - weights\n",
    "          b1: torch.tensor shape (1, h) - bias weight\n",
    "          W2: torch.tensor shape (h, d) - weights\n",
    "          b2: torch.tensor shape (1, d) - bias weight\n",
    "        returns pytorch tensor with least squred cost\n",
    "        \"\"\"\n",
    "   \n",
    "        loss = None\n",
    "        ### YOUR CODE HERE\n",
    "        ### END CODE\n",
    "        return loss\n",
    "    \n",
    "    def fit(self, data_loader, hidden_size=32, epochs=5):   \n",
    "        \"\"\" GD Learning Algorithm for Ridge Regression with pytorch\n",
    "        \n",
    "         Args:\n",
    "         data_loader: torch dataloader allows enumeration over data\n",
    "         hidden_size: int\n",
    "         epochs: int \n",
    "         \n",
    "         sets \n",
    "        \"\"\"\n",
    "        def my_init(s_to, s_from):\n",
    "            \"\"\" Standard way to initialize matrices in neural nets - you can ignore it \"\"\"\n",
    "            w = torch.zeros(s_to, s_from)\n",
    "            b = torch.zeros(s_to, 1)\n",
    "            nn.init.kaiming_uniform_(w, a=np.sqrt(5))\n",
    "            bound = 1 / np.sqrt(s_from)\n",
    "            nn.init.uniform_(b, -bound, bound)\n",
    "            #assert False\n",
    "            return torch.transpose(w, 1, 0), torch.transpose(b, 1, 0)        \n",
    "        W1, b1 = my_init(hidden_size, 784)\n",
    "        W2, b2 = my_init(784, hidden_size)\n",
    "        for i, z in enumerate([W1, b1, W2, b2]):\n",
    "            z.requires_grad_()\n",
    "\n",
    "        sgd = optim.SGD(params={W1, b1, W2, b2}, lr=0.1, weight_decay=1e-4)\n",
    "        #sgd = optim.AdamW(params={W1, b1, W2, b2}, lr=0.0001, weight_decay=1e-4)\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            epoch_count = 0\n",
    "            running_loss = 0\n",
    "            for idx, (X, y) in enumerate(data_loader):\n",
    "                sgd.zero_grad()\n",
    "                inputs = X.view(-1, 784) \n",
    "                loss = self.cost(inputs, W1, b1, W2, b2)\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_count += 1\n",
    "                #i = idx\n",
    "                running_loss += loss.item()\n",
    "                if idx % 10 == 9:   \n",
    "                    print('Running loss: {2:.3f}'.format(epoch + 1, idx + 1,  epoch_loss/epoch_count), end='\\r')\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                loss.backward()\n",
    "                sgd.step()\n",
    "                #print(torch.norm(W1))\n",
    "            print('Epoch: {0}, Mean Least Square loss: {1}'.format(epoch + 1, epoch_loss/epoch_count))\n",
    "\n",
    "        self.W1 = W1.detach() #.numpy()\n",
    "        self.W2 = W2.detach() #.numpy()\n",
    "        self.b1 = b1.detach() #.numpy()\n",
    "        self.b2 = b2.detach() #.numpy()\n",
    "        \n",
    "\n",
    "    def encode_decode(self, X):\n",
    "        \"\"\" Compute the reconstructed inputs for plotting. Should be similar to cost\n",
    "        \n",
    "        Args:\n",
    "         X: torch.tensor shape (n, d)\n",
    "         \n",
    "        Returns:\n",
    "         decoded: torch.tensor shape (n, d) using self.W1, self.b1, self.W2, self.b2\n",
    "        \"\"\"\n",
    "\n",
    "        decoded = None\n",
    "        ### YOUR CODE HERE\n",
    "        n=X.Shape[0]\n",
    "        d=X.Shape[1]\n",
    "        for i in range(n):\n",
    "            for j in range(d):\n",
    "                xhoed=max(0,(X[i,j]*self.w2+self.b2)*self.W1+self.W1)\n",
    "                1^d*()\n",
    "        ### END CODE\n",
    "        return decoded\n",
    "    \n",
    "def simple_test(hidden_size=32, epochs=1):\n",
    "    net = AutoEncoder()\n",
    "    net.fit(data_loader=train_loader, hidden_size=hidden_size,  epochs=epochs)\n",
    "    X_sample, y_sample =  next(iter(train_loader))\n",
    "    print(X_sample.shape)\n",
    "    x_vec = X_sample.view(-1, 784)\n",
    "    with torch.no_grad():\n",
    "        encoded_sample = net.encode_decode(x_vec).detach().numpy()\n",
    "    print('Input Images')\n",
    "    plot_images(x_vec.numpy(), k=x_vec.shape[0])    \n",
    "    print('Reconstructed Images')\n",
    "    plot_images(encoded_sample, k=x_vec.shape[0])\n",
    "    \n",
    "    \n",
    "\n",
    "simple_test(32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
